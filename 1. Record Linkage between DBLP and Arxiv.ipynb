{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/1.%20Record%20Linkage%20between%20DBLP%20and%20Arxiv.ipynb#Running-the-record-linkage\" data-toc-modified-id=\"Running-the-record-linkage-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Running the record linkage</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/1.%20Record%20Linkage%20between%20DBLP%20and%20Arxiv.ipynb#Outputing-matching-numbers-for-use-in-paper\" data-toc-modified-id=\"Outputing-matching-numbers-for-use-in-paper-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Outputing matching numbers for use in paper</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/1.%20Record%20Linkage%20between%20DBLP%20and%20Arxiv.ipynb#Results-of-Manually-Labelling-Coreference-Pairs\" data-toc-modified-id=\"Results-of-Manually-Labelling-Coreference-Pairs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Results of Manually Labelling Coreference Pairs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bash notebook that runs the code that does the simple coreference. It assumes that you have already run the notebook that [downloads and preprocesses the data](0.%20Download%20and%20Preprocess%20Data.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir generated/matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the record linkage\n",
    "\n",
    "There are a lot of different record linkage methods in the code, but in the end, it seemed to make sense to go with something simple but conservative: We say that a paper on DBLP appears on the arxiv if: (a) the title matches exactly, and (b) at least one of the author names matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "Total articles matched =  7313\n",
      "Total articles checked =  82427\n",
      "\n",
      "real\t0m9.733s\n",
      "user\t0m8.552s\n",
      "sys\t0m0.890s\n"
     ]
    }
   ],
   "source": [
    "time python2 matching/match_cnf_arxiv.py \\\n",
    "         --arxiv-file generated/arxiv/json/arxiv_articles.json \\\n",
    "         --dblp-file generated/dblp/all-papers.json \\\n",
    "         --output-file generated/matching/all-papers-matched-titleauthor.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The below script creates a subset of: \n",
    "\n",
    " * 25 matched articles\n",
    " * 25 unmatched articles whose titles and authors have Jaccard similarity > 0.5\n",
    "\n",
    "This will then be reviewed manually to estimate the precision and recall of this poor man's matching algorithm.\n",
    "\n",
    "This script requires about two hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Total DBLP articles = 82427\n",
      "Total matched articles = 7313\n",
      "Total close articles = 470\n",
      "Total non-close articles = 74644\n",
      "\n",
      "real\t139m3.476s\n",
      "user\t134m37.930s\n",
      "sys\t0m46.769s\n"
     ]
    }
   ],
   "source": [
    "time python2 matching/random_subsets.py \\\n",
    "         --dblp-file generated/matching/all-papers-matched-titleauthor.json \\\n",
    "         --arxiv-file generated/arxiv/json/arxiv_articles.json \\\n",
    "         --threshold 0.5 --N 25 --seed 2045230 \\\n",
    "         --prefix generated/matching/subset_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above:\n",
    "\n",
    "* \"DBLP articles\" is all of the articles that we extracted from DBLP\n",
    "* \"Matched articles\" is the number of DBLP articles for which we found a match on Arxiv\n",
    "\n",
    "(those two numbers should be the same as the previous script)\n",
    "\n",
    "* \"close articles\" are those that do not have a match on arxiv, but there *is* an arxiv article whose Jaccard similarity on both titles and authors is greater than threshold\n",
    "* \"non-close\" are the ones with no arxiv match, and no arxiv article whose Jaccard similarity on both titles and authors is greater than threshold\n",
    "\n",
    "We should have close + non-close + matched == DBLP articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing the manual analysis, I found it helpful to write one more script that processed the data set into the exact URLs that I needed to go to online.\n",
    "\n",
    "This script also randomizes the orders of the articles so that going through the list I don't know which were matched and which were merely close (although it's kind of obvious given the naming heuristic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python2 matching/subsets2csv.py \\\n",
    "    generated/matching/subset_close.json generated/matching/subset_matched.json  \\\n",
    "    > data/manually_labeled_coref_initial.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding human judgements into the file `data/manually_labeled_coref_initial.csv`, it was saved as `data/manually_labeled_coref.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputing matching numbers for use in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"dblp\": \"journals/bioinformatics/XuA13\", \n",
      "    \"title\": \"Automated target segmentation and real space fast alignment methods for high-throughput classification and averaging of crowded cryo-electron subtomograms\", \n",
      "    \"url\": \"db/journals/bioinformatics/bioinformatics29.html#XuA13\", \n",
      "    \"year\": 2013, \n",
      "    \"area\": \"bio\", \n",
      "    \"venue\": \"ISMB\", \n",
      "    \"authors\": [\n",
      "      \"Min Xu\", \n"
     ]
    }
   ],
   "source": [
    "head generated/matching/all-papers-matched-titleauthor.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82427 7313\n"
     ]
    }
   ],
   "source": [
    "TOTAL_DBLP=$(grep -c \"title\" generated/matching/all-papers-matched-titleauthor.json)\n",
    "TOTAL_MATCHED=$(grep -c \"arxiv\" generated/matching/all-papers-matched-titleauthor.json)\n",
    "echo $TOTAL_DBLP $TOTAL_MATCHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "echo \\\\newcommand{\\\\ntotaldblp}{$TOTAL_DBLP\\\\xspace} \\\n",
    "     \\\\newcommand{\\\\nmatched}{$TOTAL_MATCHED\\\\xspace} \\\n",
    "     \\\\newcommand{\\\\nunmatched}{$(( $TOTAL_DBLP - $TOTAL_MATCHED ))\\\\xspace} > figures/number_of_matched_papers.tex\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results of Manually Labelling Coreference Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manually labelling the file `data/manually_labeled_coref.csv`, 48 out of the total 50 papers in the file matched. For the two unmatched papers, it was clear that the titles were not string identical. Therefore:\n",
    "\n",
    " * Of the \"exact match\" papers in `generated/matching/subset_matched.json`, 25/25 of the (arXiv eprint, DBLP publication) pairs that were matched by the heuristc were in fact the same paper.\n",
    " * Of the \"close match\" papers in `generated/matching/subset_close.json`, 23/25 of the (arXiv eprint, DBLP publication) pairs that were matched by the heuristic were in fact the same paper.\n",
    " \n",
    " \n",
    "The 74644 non-close DBLP articles are those for which no arXiv preprint has Jaccard similarity greater than 0.5. Let's assume that none of them have arXiv preprints. Of the 470 close articles, approximate 92% have arXiv eprints, or 432 in total.\n",
    "\n",
    "This yields\n",
    "\n",
    "*  Estimated P of heuristic = 100%\n",
    "*  Estimated R of heuristic = 7313 / (7313 + 432) = 94%\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
