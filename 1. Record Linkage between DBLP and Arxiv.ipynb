{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/1.%20Record%20Linkage%20between%20DBLP%20and%20Arxiv.ipynb#Running-the-record-linkage\" data-toc-modified-id=\"Running-the-record-linkage-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Running the record linkage</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bash notebook that runs the code that does the simple coreference. It assumes that you have already run the notebook that [downloads and preprocesses the data](0.%20Download%20and%20Preprocess%20Data.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir generated/matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the record linkage\n",
    "\n",
    "There are a lot of different record linkage methods in the code, but in the end, it seemed to make sense to go with something simple but conservative: We say that a paper on DBLP appears on the arxiv if: (a) the title matches exactly, and (b) at least one of the author names matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "Total articles matched =  7313\n",
      "Total articles checked =  82427\n",
      "\n",
      "real\t0m9.733s\n",
      "user\t0m8.552s\n",
      "sys\t0m0.890s\n"
     ]
    }
   ],
   "source": [
    "time python2 matching/match_cnf_arxiv.py \\\n",
    "         --arxiv-file generated/arxiv/json/arxiv_articles.json \\\n",
    "         --dblp-file generated/dblp/all-papers.json \\\n",
    "         --output-file generated/matching/all-papers-matched-titleauthor.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The below script creates a subset of: \n",
    "\n",
    " * 25 matched articles\n",
    " * 25 unmatched articles whose titles and authors have Jaccard similarity > 0.5\n",
    "\n",
    "This will then be reviewed manually to estimate the precision and recall of this poor man's matching algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time python2 matching/random_subsets.py \\\n",
    "         --dblp-file generated/matching/all-papers-matched-titleauthor.json \\\n",
    "         --arxiv-file generated/arxiv/json/arxiv_articles.json \\\n",
    "         --threshold 0.5 --N 25 --seed 2045230 \\\n",
    "         --prefix generated/matching/subset_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above:\n",
    "\n",
    "* \"DBLP articles\" is all of the articles that we extracted from DBLP\n",
    "* \"Matched articles\" is the number of DBLP articles for which we found a match on Arxiv\n",
    "\n",
    "(those two numbers should be the same as the previous script)\n",
    "\n",
    "* \"close articles\" are those that do not have a match on arxiv, but there *is* an arxiv article whose Jaccard similarity on both titles and authors is greater than threshold\n",
    "* \"non-close\" are the ones with no arxiv match, and no arxiv article whose Jaccard similarity on both titles and authors is greater than threshold\n",
    "\n",
    "We should have close + non-close + matched == DBLP articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing the manual analysis, I found it helpful to write one more script that processed the data set into the exact URLs that I needed to go to online:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db/conf/nips/nips2014.html#ZhuLWT14\n",
      "db/conf/focs/focs2016.html#KyngS16\n",
      "db/conf/icml/icml2012.html#BachrachGMG12\n",
      "db/conf/nips/nips2009.html#Nowak09\n",
      "db/conf/nips/nips2013.html#Zhu13\n",
      "db/conf/icml/icml2015.html#TangSX15\n",
      "db/conf/icml/icml2016.html#SantoroBBWL16\n",
      "db/conf/nips/nips2016.html#Wei16\n",
      "db/conf/iros/iros2012.html#LimLK12\n",
      "db/conf/iros/iros2016.html#TamjidiCS16\n",
      "Traceback (most recent call last):\n",
      "  File \"matching/subsets2csv.py\", line 53, in <module>\n",
      "    main()\n",
      "  File \"matching/subsets2csv.py\", line 43, in main\n",
      "    raise Exception(\"Cannot find dblp id:\\n\"+str(art))\n",
      "Exception: Cannot find dblp id:\n",
      "{u'bow_authors': [[u'hao', u'peng'], [u'shandian', u'zhe'], [u'xiao', u'zhang'], [u'yuan', u'qi']], u'title_dist': 0.7142857142857143, u'area': u'mlmining', u'url': None, u'closest_arxiv': {u'category': u'stat.ML', u'bow_authors': [[u'hao', u'peng'], [u'shandian', u'zhe'], [u'yuan', u'qi']], u'title': u'Asynchronous Distributed Variational Gaussian Processes for Regression', u'year': 2017, u'submit': u'22-Apr-2017', u'bow_title': [u'asynchronous', u'distributed', u'variational', u'gaussian', u'processes', u'regression'], u'authors': u'Hao Peng, Shandian Zhe and Yuan Qi', u'id': u'1704.06735'}, u'venue': u'ICML', u'authors': [u'Hao Peng', u'Shandian Zhe', u'Xiao Zhang', u'Yuan Qi'], u'bow_title': [u'asynchronous', u'distributed', u'variational', u'gaussian', u'process', u'regression'], u'year': 2017, u'title': u'Asynchronous Distributed Variational Gaussian Process for Regression', u'author_dist': 0.75}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "python2 matching/subsets2csv.py \\\n",
    "    generated/matching/subset__close.json generated/matching/subset__match.json  \\\n",
    "    > data/manually_labeled_coref.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
